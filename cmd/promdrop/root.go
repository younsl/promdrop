package main

import (
	"fmt"
	"log"
	"os"
	"path/filepath"
	"sort"

	"github.com/spf13/cobra"
	"gopkg.in/yaml.v3"

	// Internal packages
	"younsl/promdrop/internal/metrics"
	"younsl/promdrop/internal/report"
	"younsl/promdrop/internal/utils"
)

const (
	// Define maxRegexLength as a constant
	maxRegexLength = 1000
)

var (
	// Build info (set via ldflags)
	version = "dev"
	commit  = "unknown"

	// CLI flags
	jsonFilePath string
	txtOutputDir string
	outputFile   string
)

// Define struct for the per-job YAML configuration
type JobConfig struct {
	JobName              string               `yaml:"job_name"`
	MetricRelabelConfigs []report.RelabelRule `yaml:"metric_relabel_configs"`
}

// rootCmd represents the base command when called without any subcommands
var rootCmd = &cobra.Command{
	Use:     "promdrop",
	Version: version,
	Short:   "Generates Prometheus relabel configs to drop unused metrics",
	Long: `PromDrop analyzes prometheus-metrics.json (e.g., generated by Mimirtool)
identifies unused metrics (additional_metric_counts),
and generates Prometheus metric_relabel_configs YAML file(s) to drop them per job.

It also generates .txt files listing the metrics to be dropped for each job.`,
	Example: `promdrop --file prometheus-metrics.json --txt-output-dir unused --output combined_relabel_configs.yaml`,
	Args:    cobra.NoArgs,
	Run: func(cmd *cobra.Command, args []string) {
		if err := runPromDropLogic(); err != nil {
			log.Fatalf("[Error] %v", err)
		}
	},
}

// Execute adds all child commands to the root command and sets flags appropriately.
// This is called by main.main(). It only needs to happen once to the rootCmd.
func Execute() {
	err := rootCmd.Execute()
	if err != nil {
		os.Exit(1)
	}
}

func init() {
	// Set custom version template with commit info
	rootCmd.SetVersionTemplate("promdrop version {{.Version}} ({{printf \"commit: %s\" \"" + commit + "\"}})\n")

	// Define flags
	rootCmd.Flags().StringVarP(&jsonFilePath, "file", "f", "", "Input prometheus-metrics.json file path (required)")
	rootCmd.Flags().StringVarP(&txtOutputDir, "txt-output-dir", "t", "unused", "Output directory for .txt files")
	rootCmd.Flags().StringVarP(&outputFile, "output", "o", "combined_relabel_configs.yaml", "Output file path for combined YAML")

	// Mark flags required
	if err := rootCmd.MarkFlagRequired("file"); err != nil {
		fmt.Fprintf(os.Stderr, "Error marking flag 'file' as required: %v\n", err)
		os.Exit(1)
	}
}

// calculateGroupSummary calculates total metrics and unique prefixes from GroupInfo
func calculateGroupSummary(groupInfo []metrics.GroupInfo) (totalMetrics int, numPrefixGroups int) {
	prefixSet := make(map[string]bool)
	for _, info := range groupInfo {
		totalMetrics += info.Count
		prefixSet[info.Prefix] = true
	}
	numPrefixGroups = len(prefixSet)
	return
}

// --- Refactored Functions ---

// loadAndParseMetrics loads and parses the JSON file, calculates total unique metrics.
func loadAndParseMetrics(filePath string) (jobMetricsMap map[string][]string, summaryData []metrics.JobMetricSummary, totalUniqueMetrics int, err error) {
	jsonFileAbs, err := filepath.Abs(filePath)
	if err != nil {
		return nil, nil, 0, fmt.Errorf("failed to get absolute path for input JSON file: %w", err)
	}

	log.Printf("[Info] Reading input JSON file: '%s'...\n", jsonFileAbs)
	jobMetricsMap, summaryData, err = metrics.ParseAndExtractMetrics(jsonFileAbs)
	if err != nil {
		return nil, nil, 0, fmt.Errorf("failed to process data: %w", err)
	}

	if len(summaryData) == 0 {
		return nil, nil, 0, fmt.Errorf("no unused metrics data found to process (check additional_metric_counts)")
	}
	log.Printf("[Info] Found unused metrics for %d jobs.\n", len(summaryData))

	uniqueMetricSet := make(map[string]bool)
	for _, metrics := range jobMetricsMap {
		for _, metric := range metrics {
			uniqueMetricSet[metric] = true
		}
	}
	totalUniqueMetrics = len(uniqueMetricSet)

	return jobMetricsMap, summaryData, totalUniqueMetrics, nil
}

// generateInitialOutputs prints the summary table and generates the summary file.
func generateInitialOutputs(summaryData []metrics.JobMetricSummary, txtDir, jsonPath string) {
	fmt.Println("\n--- Unused Metric Summary ---")
	report.PrintSummaryTable(summaryData)
	fmt.Println("----------------------------")

	// Generate summary file
	summaryFilePath := filepath.Join(txtDir, "summary.txt") // Construct path for logging
	log.Printf("[Info] Attempting to generate summary file: '%s'...", summaryFilePath)
	report.GenerateSummaryFile(txtDir, summaryData, jsonPath)
}

// generateRelabelConfigsYAML handles user confirmation and generates output files.
func generateRelabelConfigsYAML(jobMetricsMap map[string][]string, summaryData []metrics.JobMetricSummary, txtDir, yamlOutputFile string, totalUniqueMetrics int) error {
	// --- User confirmation step ---
	if !utils.GetUserConfirmation() {
		fmt.Println("\n[Info] Operation cancelled by user.")
		return nil // User cancelled, not an error
	}

	// --- Start .txt and YAML generation ---
	fmt.Println("\n[Info] Starting .txt and YAML file generation...")
	processedJobCount := 0
	rootNode := yaml.Node{Kind: yaml.SequenceNode}

	// Setup output directories/files
	err := os.MkdirAll(txtDir, 0755)
	if err != nil {
		return fmt.Errorf("failed to create .txt output directory ('%s'): %w", txtDir, err)
	}
	txtOutputDirAbs, err := filepath.Abs(txtDir)
	if err != nil {
		return fmt.Errorf("failed to get absolute path for .txt output directory: %w", err)
	}
	outputFileAbs, err := filepath.Abs(yamlOutputFile)
	if err != nil {
		return fmt.Errorf("failed to get absolute path for combined YAML file: %w", err)
	}

	fmt.Printf("[Info] Output directory for .txt files: '%s'\n", txtOutputDirAbs)
	fmt.Printf("[Info] Output file for combined YAML: '%s'\n", outputFileAbs)

	// Sort summaryData for consistent output order
	sort.SliceStable(summaryData, func(i, j int) bool {
		return summaryData[i].JobName < summaryData[j].JobName
	})

	for _, item := range summaryData {
		jobName := item.JobName
		metrics := jobMetricsMap[jobName]
		metricCountForJob := item.MetricCount

		// Generate the .txt file first (even if empty)
		report.GenerateTxtFile(txtOutputDirAbs, jobName, metrics)

		if metricCountForJob == 0 {
			log.Printf("[Warning] Metric list for job '%s' is empty. Skipping YAML rule generation for this job.", jobName)
			continue // Skip YAML generation for this job
		}

		fmt.Printf("--- Processing (YAML): Job: %s ---\n", jobName)
		fmt.Printf("[Info] Found %d metrics\n", metricCountForJob)

		// Generate YAML rules
		relabelRules, groupInfo := report.GenerateRelabelRules(metrics, maxRegexLength)
		fmt.Printf("[Info] Grouped into %d rule entries\n", len(relabelRules))

		// Print group summary to console
		report.PrintGroupSummary(groupInfo)

		// Calculate summary for comment
		totalMetricsInJob, numPrefixGroups := calculateGroupSummary(groupInfo)
		numRulesGenerated := len(relabelRules)
		summaryComment := fmt.Sprintf("# Summary: %d of %d unused metrics / %d prefix groups / %d rules generated", totalMetricsInJob, totalUniqueMetrics, numPrefixGroups, numRulesGenerated)

		// Construct JobConfig
		jobConfig := JobConfig{
			JobName:              jobName,
			MetricRelabelConfigs: relabelRules,
		}

		// Convert JobConfig to yaml.Node
		var jobNode yaml.Node
		err = jobNode.Encode(jobConfig)
		if err != nil {
			return fmt.Errorf("failed to encode job config to YAML node for job '%s': %w", jobName, err)
		}

		// Add the summary comment
		jobNode.HeadComment = summaryComment

		// Add the job node to the root sequence
		rootNode.Content = append(rootNode.Content, &jobNode)
		processedJobCount++
	}

	// --- Marshal and save the final combined YAML file ---
	if processedJobCount > 0 {
		outFile, err := os.Create(outputFileAbs)
		if err != nil {
			return fmt.Errorf("failed to create output YAML file '%s': %w", outputFileAbs, err)
		}
		defer outFile.Close()

		encoder := yaml.NewEncoder(outFile)
		encoder.SetIndent(2)

		err = encoder.Encode(&rootNode)
		if err != nil {
			return fmt.Errorf("failed to encode final YAML node structure: %w", err)
		}
		err = encoder.Close()
		if err != nil {
			return fmt.Errorf("failed to close YAML encoder: %w", err)
		}

		fmt.Printf("\n[Success] Combined result saved to '%s'\n", outputFileAbs)

	} else {
		fmt.Println("\n[Info] No jobs with metrics processed, combined YAML file not generated.")
	}

	fmt.Printf("[Complete] Processed %d jobs and generated YAML configuration for %d unique unused metrics.\n", processedJobCount, totalUniqueMetrics)
	return nil
}

// runPromDropLogic orchestrates the main application logic.
func runPromDropLogic() error {
	// Ensure txtOutputDir exists before generating summary
	txtOutputDirAbs, err := filepath.Abs(txtOutputDir)
	if err != nil {
		return fmt.Errorf("failed to get absolute path for .txt output directory: %w", err)
	}
	err = os.MkdirAll(txtOutputDirAbs, 0755) // Create the directory
	if err != nil {
		return fmt.Errorf("failed to create .txt output directory ('%s'): %w", txtOutputDirAbs, err)
	}
	log.Printf("[Info] Ensured .txt output directory exists: '%s'", txtOutputDirAbs) // Log path

	// 1. Load and Parse Metrics
	jobMetricsMap, summaryData, totalUniqueMetrics, err := loadAndParseMetrics(jsonFilePath)
	if err != nil {
		// Check if the error is the specific "no data" error
		if err.Error() == "no unused metrics data found to process (check additional_metric_counts)" {
			fmt.Println("[Info] No unused metrics data found to process (check additional_metric_counts).")
			return nil
		}
		return err
	}

	generateInitialOutputs(summaryData, txtOutputDirAbs, jsonFilePath)

	if err := generateRelabelConfigsYAML(jobMetricsMap, summaryData, txtOutputDirAbs, outputFile, totalUniqueMetrics); err != nil {
		return err
	}

	return nil
}
